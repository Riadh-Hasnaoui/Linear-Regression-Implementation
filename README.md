# PrÃ©diction Profit Franchise

Un projet d'implÃ©mentation complÃ¨te de rÃ©gression linÃ©aire pour prÃ©dire les profits de franchises de restaurants basÃ© sur la population des villes.

## ğŸ“‹ Vue d'ensemble du projet

Ce projet implÃ©mente un modÃ¨le de rÃ©gression linÃ©aire simple pour prÃ©dire les profits mensuels moyens d'une franchise de restaurant en fonction de la population de la ville. C'est une dÃ©monstration pratique des concepts fondamentaux du machine learning.

## ğŸ¯ Objectif

Construire un modÃ¨le de rÃ©gression linÃ©aire capable de :
- Analyser la relation entre la population d'une ville et les profits d'un restaurant
- PrÃ©dire les profits potentiels pour de nouvelles villes candidates
- Identifier les opportunitÃ©s d'expansion commerciale optimales

## ğŸ“Š Ensemble de donnÃ©es

- **Variables d'entrÃ©e (x)** : Population des villes (en unitÃ©s de 10,000)
- **Variables de sortie (y)** : Profits mensuels (en unitÃ©s de $10,000)
- **Nombre d'exemples** : 97 villes
- **Format** : DonnÃ©es NumPy (tableaux 1D)

## ğŸ”§ ImplÃ©mentation

### Fonction de coÃ»t
```
J(w,b) = (1/2m) Î£(f_w,b(x^(i)) - y^(i))Â²
```

### Gradient descent
```
âˆ‚J/âˆ‚b = (1/m) Î£(f_w,b(x^(i)) - y^(i))
âˆ‚J/âˆ‚w = (1/m) Î£(f_w,b(x^(i)) - y^(i))x^(i)
```

### ModÃ¨le linÃ©aire
```
f_w,b(x) = wx + b
```

## ğŸ“ Structure du projet

```
PrÃ©diction-Profit-Franchise/
â”œâ”€â”€ PrÃ©diction Profit Franchise.ipynb    # Notebook principal
â”œâ”€â”€ utils.py                              # Fonctions utilitaires
â”œâ”€â”€ public_tests.py                       # Tests unitaires
â”œâ”€â”€ README.md                             # Documentation
â”œâ”€â”€ data/                                 # DonnÃ©es du projet
â”‚   â””â”€â”€ restaurant_data.txt
â””â”€â”€ requirements.txt                      # DÃ©pendances
```

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

```bash
Python 3.7+
NumPy
Matplotlib
```

### Installation

1. Cloner le repository
```bash
git clone https://github.com/votre-nom/Prediction-Profit-Franchise.git
cd Prediction-Profit-Franchise
```

2. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

3. Ouvrir le notebook Jupyter
```bash
jupyter notebook "PrÃ©diction Profit Franchise.ipynb"
```

## ğŸ’» Utilisation

### EntraÃ®ner le modÃ¨le

```python
# Initialiser les paramÃ¨tres
initial_w = 0.
initial_b = 0.

# HyperparamÃ¨tres
iterations = 1500
alpha = 0.01  # Taux d'apprentissage

# EntraÃ®ner le modÃ¨le
w, b, _, _ = gradient_descent(
    x_train, y_train, 
    initial_w, initial_b, 
    compute_cost, 
    compute_gradient, 
    alpha, 
    iterations
)
```

### Faire des prÃ©dictions

```python
# PrÃ©dire le profit pour une ville de 35,000 habitants
population = 3.5  # 35,000 / 10,000
profit = w * population + b
print(f'Profit prÃ©dit: ${profit*10000:.2f}')
```

## ğŸ“ˆ RÃ©sultats

AprÃ¨s 1500 itÃ©rations avec un taux d'apprentissage de 0.01 :

| MÃ©trique | Valeur |
|----------|--------|
| ParamÃ¨tre w | 1.166 |
| ParamÃ¨tre b | -3.630 |
| CoÃ»t final | 4.49 |
| Population 35,000 | $4,519.77 |
| Population 70,000 | $45,342.45 |

## ğŸ§ª Tests

ExÃ©cuter les tests unitaires :

```python
from public_tests import *

# Test de la fonction de coÃ»t
compute_cost_test(compute_cost)

# Test du gradient
compute_gradient_test(compute_gradient)
```

### RÃ©sultats attendus

```
âœ“ Cost at initial w: 75.203
âœ“ Gradient at initial w, b (zeros): -65.329, -5.839
âœ“ All tests passed!
```

## ğŸ“š Concepts clÃ©s

- **RÃ©gression linÃ©aire** : ModÃ¨le statistique pour prÃ©dire une variable continue
- **Fonction de coÃ»t** : Mesure la performance du modÃ¨le (erreur quadratique moyenne)
- **Gradient descent** : Algorithme d'optimisation itÃ©rative
- **ParamÃ¨tres** : Poids (w) et biais (b) du modÃ¨le
- **Taux d'apprentissage** : ContrÃ´le la taille des pas d'optimisation

## ğŸ“Š Visualisations

Le projet inclut :
- Graphique en nuage de points des donnÃ©es d'entraÃ®nement
- Ligne de rÃ©gression linÃ©aire ajustÃ©e
- Convergence de la fonction de coÃ»t

## ğŸ”¬ AmÃ©liorations possibles

- Ajouter une validation croisÃ©e
- ImplÃ©menter une rÃ©gularisation (L1/L2)
- Ã‰tendre Ã  la rÃ©gression multiple (plusieurs variables)
- Ajouter de la normalisation des donnÃ©es
- Comparer avec d'autres modÃ¨les (polynomial, Ridge, Lasso)

## ğŸ“ Notes techniques

- Les donnÃ©es sont stockÃ©es sous forme de tableaux NumPy 1D
- L'implÃ©mentation utilise uniquement NumPy (pas de scikit-learn)
- Le modÃ¨le utilise la descente de gradient batch (tous les exemples)
- La convergence est garantie pour ce problÃ¨me simple et convexe

## ğŸ‘¥ Apprentissage pÃ©dagogique

Ce projet dÃ©montre :
- ImplÃ©mentation manuelle d'algorithmes de ML
- ComprÃ©hension du calcul diffÃ©rentiel appliquÃ©
- Visualisation et interprÃ©tation des rÃ©sultats
- Bonnes pratiques de programmation Python

## ğŸ“„ Licence

Ce projet est sous licence MIT.

## ğŸ¤ Contributions

Les contributions sont bienvenues ! N'hÃ©sitez pas Ã  :
- Soumettre des pull requests
- Signaler des bugs
- Proposer des amÃ©liorations

## ğŸ“§ Contact

Pour toute question ou suggestion, veuillez ouvrir une issue sur GitHub.

---

**CrÃ©Ã© avec â¤ï¸ pour l'apprentissage du machine learning**
